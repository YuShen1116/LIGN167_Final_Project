{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chinese Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/NEU_cn.txt','r',encoding='utf-8') as reader:\n",
    "    with open('./data/NEU_cn_preprocessed.txt','wb+') as writer:\n",
    "        lines = reader.readlines()\n",
    "        for l in lines:\n",
    "            tmp = ' '.join(jieba.cut(l))\n",
    "            writer.write(tmp.encode())\n",
    "    writer.close()\n",
    "reader.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Install nltk package\n",
    "2. import nltk and run nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/NEU_en.txt','r') as reader:\n",
    "    with open('./data/NEU_en_preprocessed.txt','w+') as writer:\n",
    "        lines = reader.readlines()\n",
    "        for l in lines:\n",
    "            tmp = ' '.join(word_tokenize(l))\n",
    "            writer.write(tmp+'\\n')\n",
    "    writer.close()\n",
    "reader.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/NEU_cn_preprocessed.txt','r',encoding='utf-8') as cn:\n",
    "    with open('./data/NEU_en_preprocessed.txt','r') as en:\n",
    "        with open('./data/train.txt','wb+') as train:\n",
    "            with open('./data/test.txt','wb+') as test:\n",
    "                X, Y = en.readlines(), cn.readlines()\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "                                X, Y, test_size=0.25, random_state=23)\n",
    "                train_size = len(X_train)\n",
    "                test_size = len(X_test)\n",
    "                for i in range(train_size):\n",
    "                    train.write((X_train[i].rstrip('\\n')+'<------>'+Y_train[i]).encode())\n",
    "                for i in range(test_size):\n",
    "                    test.write((X_test[i].rstrip('\\n')+'<------>'+Y_test[i]).encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
